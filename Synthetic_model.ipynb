{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adlerviton/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adlerviton/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prep_financial_phrasebank import clean_text\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uh bad uh down uh uh is maybe bad bad uh bad i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up good uh up great great is more up is up</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not up down less not less is</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>down maybe down maybe more is is maybe more up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uh is up up maybe uh great great is uh up up is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>good maybe maybe maybe uh up better up great g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>less up not maybe maybe less less same</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>is maybe is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>down maybe down maybe not up maybe uh up not n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>is down more same</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "0     uh bad uh down uh uh is maybe bad bad uh bad i...      0\n",
       "1            up good uh up great great is more up is up      2\n",
       "2                          not up down less not less is      1\n",
       "3     down maybe down maybe more is is maybe more up...      1\n",
       "4       uh is up up maybe uh great great is uh up up is      2\n",
       "...                                                 ...    ...\n",
       "1995  good maybe maybe maybe uh up better up great g...      2\n",
       "1996             less up not maybe maybe less less same      1\n",
       "1997                                        is maybe is      2\n",
       "1998  down maybe down maybe not up maybe uh up not n...      1\n",
       "1999                                  is down more same      1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"sentence\", \"label\"]\n",
    "synthetic_df = pd.DataFrame(columns=columns)\n",
    "for i in range(2000):\n",
    "    max_length = 20\n",
    "    length = int(np.round(np.random.uniform(0.15, 1) * max_length))\n",
    "    types = 2\n",
    "    sent = int(np.round(np.random.uniform(0, 1) * types))\n",
    "    if sent == 1:\n",
    "        rand_text = [\n",
    "            random.choice(\n",
    "                (\"uh\", \"not\", \"up\", \"down\", \"maybe\", \"is\", \"less\", \"more\", \"same\")\n",
    "            )\n",
    "            for _ in range(length)\n",
    "        ]\n",
    "    elif sent == 2:\n",
    "        rand_text = [\n",
    "            random.choice(\n",
    "                (\"good\", \"uh\", \"up\", \"maybe\", \"better\", \"is\", \"more\", \"great\")\n",
    "            )\n",
    "            for _ in range(length)\n",
    "        ]\n",
    "    elif sent == 0:\n",
    "        rand_text = [\n",
    "            random.choice(\n",
    "                (\"bad\", \"uh\", \"down\", \"maybe\", \"worse\", \"is\", \"less\", \"terrible\")\n",
    "            )\n",
    "            for _ in range(length)\n",
    "        ]\n",
    "    random_text = \" \".join(rand_text)\n",
    "    synthetic_df.loc[i] = [random_text, sent]  # Add rand_text to synthetic_df\n",
    "\n",
    "synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_financial_phrasebank import (\n",
    "    tokenize_financial_phrasebank,\n",
    "    generate_data_word2vec,\n",
    ")\n",
    "\n",
    "\n",
    "def aggregate_fake_splits(fakedata):\n",
    "    \"\"\"\n",
    "    Aggregate all splits of financial_phrasebank\n",
    "    \"\"\"\n",
    "    df = fakedata\n",
    "    df = tokenize_financial_phrasebank(df)\n",
    "    X_train, y_train, X_test, y_test = generate_data_word2vec(df)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.87146   , -1.0187988 ,  0.92822266, ...,  2.5339355 ,\n",
       "         -1.142395  ,  4.5161133 ],\n",
       "        [-8.705078  , -0.3168335 ,  1.310791  , ...,  2.758789  ,\n",
       "         -4.491394  ,  9.781006  ],\n",
       "        [-4.5458984 , -1.5222168 ,  1.439209  , ...,  2.3752441 ,\n",
       "         -2.239746  ,  4.902832  ],\n",
       "        ...,\n",
       "        [-6.1606445 ,  2.1430664 , -0.5197754 , ...,  1.1033936 ,\n",
       "         -2.443451  ,  8.682434  ],\n",
       "        [-2.045288  , -0.01757812,  0.4958496 , ...,  1.0234375 ,\n",
       "         -0.7989807 ,  2.8154297 ],\n",
       "        [-4.5075073 , -0.35559082,  1.1030273 , ...,  2.5355225 ,\n",
       "         -2.8240051 ,  5.9662476 ]], dtype=float32),\n",
       " array([1, 2, 1, ..., 0, 0, 1]),\n",
       " array([[ -4.713867  ,   1.0246582 ,   0.3881836 , ...,   2.0249023 ,\n",
       "          -1.9231567 ,   7.689453  ],\n",
       "        [ -5.4991455 ,  -0.07495117,   1.1713867 , ...,   2.3410645 ,\n",
       "          -2.0603027 ,   7.3081055 ],\n",
       "        [ -5.9834595 ,  -1.3416748 ,   0.9786377 , ...,   3.7557373 ,\n",
       "          -2.6251526 ,   8.717651  ],\n",
       "        ...,\n",
       "        [ -2.1611328 ,   0.3491211 ,   0.15209961, ...,   0.20361328,\n",
       "          -1.6034546 ,   2.2080078 ],\n",
       "        [-11.765625  ,  -0.36480713,  -0.9572754 , ...,   3.3217773 ,\n",
       "          -4.6465454 ,  13.357178  ],\n",
       "        [ -2.1487427 ,   0.37390137,  -0.20666504, ...,  -0.16442871,\n",
       "          -1.3102417 ,   1.9847412 ]], dtype=float32),\n",
       " array([1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "        0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 1, 2, 2, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        2, 2, 1, 0, 1, 1, 0, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2,\n",
       "        2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 2, 1, 0, 1, 0, 2,\n",
       "        1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1,\n",
       "        2, 2, 2, 0, 0, 1, 0, 2, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 2,\n",
       "        2, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1,\n",
       "        0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        2, 1, 1, 2, 2, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1,\n",
       "        0, 0, 1, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 0, 2, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 2, 2, 0,\n",
       "        1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 0,\n",
       "        1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1,\n",
       "        2, 1, 1, 2, 2, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_fake_splits(synthetic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment() -> None:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # prepare training and testing data\n",
    "    X_train, y_train, X_test, y_test = aggregate_fake_splits(synthetic_df)\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "    print(\"word2vec (train):\", clf.score(X_train, y_train))\n",
    "    print(\"word2vec (test):\", clf.score(X_test, y_test))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec (train): 0.9829545454545454\n",
      "word2vec (test): 0.9823232323232324\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
